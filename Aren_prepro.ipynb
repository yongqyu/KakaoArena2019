{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "magazine_path = '/data/private/Arena/datasets/magazine.json'\n",
    "metadata_path = '/data/private/Arena/datasets/metadata.json'\n",
    "users_path = '/data/private/Arena/datasets/users.json'\n",
    "predict_path = '/data/private/Arena/datasets/predict/'\n",
    "read_path = '/data/private/Arena/datasets/read/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magazine -> keyword list\n",
    "magazine_list = []\n",
    "for line in open(magazine_path, 'r', encoding='utf-8'):\n",
    "    magazine_list.append(json.loads(line))\n",
    "metadata_list = []\n",
    "for line in open(metadata_path, 'r', encoding='utf-8'):\n",
    "    metadata_list.append(json.loads(line))\n",
    "users_list = []\n",
    "for line in open(users_path, 'r', encoding='utf-8'):\n",
    "    users_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'magazine_tag_list': ['브런치북', '육아일기', '대화법', '들려주고픈이야기'], 'id': '38842'},\n",
       " {'magazine_id': 8982,\n",
       "  'user_id': '@bookdb',\n",
       "  'title': '사진으로 옮기기에도 아까운, 리치필드 국립공원',\n",
       "  'keyword_list': ['여행', '호주', '국립공원'],\n",
       "  'display_url': 'https://brunch.co.kr/@bookdb/782',\n",
       "  'sub_title': '세상 어디에도 없는 호주 Top 10',\n",
       "  'reg_ts': 1474944427000,\n",
       "  'article_id': 782,\n",
       "  'id': '@bookdb_782'},\n",
       " {'keyword_list': [],\n",
       "  'following_list': ['@perytail', '@brunch'],\n",
       "  'id': '#901985d8bc4c481805c4a4f911814c4a'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magazine_list[0], metadata_list[0], users_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keyword / reader / writer dict and list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['unk', 'pad']\n",
    "for data in tqdm_notebook(magazine_list):\n",
    "    for keyword in data['magazine_tag_list']:\n",
    "        if keyword not in keyword_list:\n",
    "            keyword_list.append(keyword)\n",
    "for data in tqdm_notebook(metadata_list):\n",
    "    for keyword in data['keyword_list']:\n",
    "        if keyword not in keyword_list:\n",
    "            keyword_list.append(keyword)\n",
    "for data in tqdm_notebook(users_list):\n",
    "    for keyword in data['keyword_list']:\n",
    "        if keyword not in keyword_list:\n",
    "            keyword_list.append(keyword)\n",
    "            \n",
    "keyword_dict = {}\n",
    "for i, keyword in enumerate(keyword_list):\n",
    "    keyword_dict[keyword] = i\n",
    "    \n",
    "np.save('/data/private/Arena/prepro_results/keyword_dict.npy', keyword_dict)\n",
    "np.save('/data/private/Arena/prepro_results/keyword_list.npy', keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057201876ab24c718b87e67d5d2a4e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=310758), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id2writer = ['unk']\n",
    "id2reader = ['unk']\n",
    "for data in tqdm_notebook(users_list):\n",
    "    id2reader.append(data['id'])\n",
    "    for writer in data['following_list']:\n",
    "        if writer not in id2writer:\n",
    "            id2writer.append(writer)\n",
    "\n",
    "reader2id = {}\n",
    "for i, reader in enumerate(id2reader):\n",
    "    reader2id[reader] = i\n",
    "    \n",
    "writer2id = {}\n",
    "for i, writer in enumerate(id2writer):\n",
    "    writer2id[writer] = i\n",
    "    \n",
    "np.save('/data/private/Arena/prepro_results/id2reader.npy', id2reader)\n",
    "np.save('/data/private/Arena/prepro_results/reader2id.npy', reader2id)\n",
    "np.save('/data/private/Arena/prepro_results/id2writer.npy', id2writer)\n",
    "np.save('/data/private/Arena/prepro_results/writer2id.npy', writer2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab92dc97d9f04c058e4e648dcc21ae3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27967), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "magazine2id = {'unk':0}\n",
    "id2magazine = ['unk']\n",
    "for data in tqdm_notebook(magazine_list):\n",
    "    id_ = int(data['id'])\n",
    "    \n",
    "    if id_ not in id2magazine:\n",
    "        magazine2id[id_] = len(id2magazine)\n",
    "        id2magazine.append(id_)\n",
    "        \n",
    "np.save('/data/private/Arena/prepro_results/id2magazine.npy', id2magazine)\n",
    "np.save('/data/private/Arena/prepro_results/magazine2id.npy', magazine2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reader / item 2 elements & item dict and list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6441fafcecbd4c98aa7c8ca007058d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=310758), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reader2elem = {'unk':0}\n",
    "follow_list = []\n",
    "follow_maxlen = 12\n",
    "keyword_maxlen = 0\n",
    "for data in tqdm_notebook(users_list):\n",
    "    #follow_list.append(len(data['following_list']))\n",
    "    id_ = reader2id[data['id']]\n",
    "    follow = [writer2id['unk']] * (follow_maxlen-len(data['following_list'])) + \\\n",
    "             list(map(writer2id.get, data['following_list'][-follow_maxlen:]))\n",
    "    reader2elem[id_] = follow\n",
    "\n",
    "    #reader2elem[id_] = \n",
    "    #if keyword_maxlen < len(data['keyword_list']):\n",
    "    #    keyword_maxlen = len(data['keyword_list'])\n",
    "    #if data['keyword_list']:\n",
    "    #    keywords = [kw['keyword'].split(' ') for kw in data['keyword_list'] if kw['cnt'] > 10]\n",
    "    #    keywords = list(set([a for b in keywords for a in b]))\n",
    "    #    print(keywords)\n",
    "    #    if keyword_maxlen < len(keywords):\n",
    "    #        keyword_maxlen = len(keywords)\n",
    "\n",
    "np.save('/data/private/Arena/prepro_results/reader2elem.npy', reader2elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db666fd1344440c2b8a3f3fa6dfa2343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=310758), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywordlen_list = []\n",
    "for data in tqdm_notebook(users_list):\n",
    "    keywordlen_list.append(len(data['keyword_list']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 310758)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(keywordlen_list)[280000], len(keywordlen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.420954569150272\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(follow_list))\n",
    "print(sorted(follow_list)[int(len(follow_list)*0.85)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c2db4fe84742a0903e7562b2b42cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=643104), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'id2magazine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-d782b0dd8e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/private/Arena/prepro_results/item_list.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/private/Arena/prepro_results/item2elem.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem2elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/private/Arena/prepro_results/id2magazine.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2magazine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/private/Arena/prepro_results/magazine2id.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagazine2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'id2magazine' is not defined"
     ]
    }
   ],
   "source": [
    "keywd_maxlen = 5\n",
    "item2elem = {0:[0,0,0,0,0,0,0,0]}\n",
    "item_list = ['unk']\n",
    "item_dict = {'unk':0}\n",
    "\n",
    "for data in tqdm_notebook(metadata_list):\n",
    "    if item_dict.get(data['id']) == None:\n",
    "        item_dict[data['id']] = len(item_list)\n",
    "        item_list.append(data['id'])\n",
    "        \n",
    "    if data['keyword_list']:\n",
    "        keywd = [keyword_dict['pad']] * (keywd_maxlen-len(data['keyword_list'])) + \\\n",
    "                list(map(keyword_dict.get, data['keyword_list'][::-1]))\n",
    "    else:\n",
    "        keywd = [keyword_dict['unk']] * keywd_maxlen\n",
    "    writer = writer2id[data['user_id']]\n",
    "    reg_ts = int(data['reg_ts'])/1000\n",
    "    if magazine2id.get(int(data['magazine_id'])) == None:\n",
    "        magazine2id[int(data['magazine_id'])] = len(id2magazine)\n",
    "        id2magazine.append(int(data['magazine_id']))\n",
    "    mag_id = magazine2id[int(data['magazine_id'])]\n",
    "    \n",
    "    item2elem[item_dict[data['id']]] = [writer] + keywd + [reg_ts, mag_id]\n",
    "        \n",
    "np.save('/data/private/Arena/prepro_results/item_dict.npy', item_dict)\n",
    "np.save('/data/private/Arena/prepro_results/item_list.npy', item_list)\n",
    "np.save('/data/private/Arena/prepro_results/item2elem.npy', item2elem)\n",
    "np.save('/data/private/Arena/prepro_results/id2magazine.npy', id2magazine)\n",
    "np.save('/data/private/Arena/prepro_results/magazine2id.npy', magazine2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Tensor & Writer 2 items (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071c38df6d8e401fb57db998a2d83f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=643104), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "\n",
    "id2writer = np.load('/data/private/Arena/prepro_results/id2writer.npy')\n",
    "writer2id = np.load('/data/private/Arena/prepro_results/writer2id.npy', allow_pickle=True).item()\n",
    "keyword_dict = np.load('/data/private/Arena/prepro_results/keyword_dict.npy', allow_pickle=True).item()\n",
    "keyword_list = np.load('/data/private/Arena/prepro_results/keyword_list.npy')\n",
    "valid_writer_keywd = []\n",
    "\n",
    "\n",
    "for data in tqdm_notebook(metadata_list):\n",
    "    if data['keyword_list']:\n",
    "        keywd = [keyword_dict['pad']] * (keywd_maxlen-len(data['keyword_list'])) + \\\n",
    "                list(map(keyword_dict.get, data['keyword_list'][::-1]))\n",
    "    else:\n",
    "        keywd = [keyword_dict['unk']] * keywd_maxlen\n",
    "    writer = writer2id[data['user_id']]\n",
    "    reg_ts = int(data['reg_ts'])\n",
    "    meg_id = int(data['magazine_id'])\n",
    "    item_id = item_dict[data['id']]\n",
    "    \n",
    "    valid_writer_keywd.append([item_id, writer] + keywd + [reg_ts, meg_id])\n",
    "\n",
    "valid_writer_keywd = torch.from_numpy(np.array(valid_writer_keywd))\n",
    "torch.save(valid_writer_keywd, '/data/private/Arena/prepro_results/valid_writer_keywd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbd8dbe1f984a83a17fbb0a49741fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=643104), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "item_dict = np.load('/data/private/Arena/prepro_results/item_dict.npy', allow_pickle=True).item()\n",
    "item_list = np.load('/data/private/Arena/prepro_results/item_list.npy')\n",
    "\n",
    "writerid2items = {}\n",
    "for data in tqdm_notebook(metadata_list):\n",
    "    user_id = writer2id[data['user_id']]\n",
    "    id_ = item_dict[data['id']]\n",
    "    keyword = keyword_dict[data['keyword_list'][0] if data['keyword_list'] is True else '없음']\n",
    "    \n",
    "    if writerid2items.get(user_id) == None:\n",
    "        writerid2items[user_id] = [[id_, user_id, keyword]]\n",
    "    else:\n",
    "        writerid2items[user_id].append([id_, user_id, keyword])\n",
    "        \n",
    "np.save('/data/private/Arena/prepro_results/writerid2items.npy', writerid2items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 2019022 : Reader 2 Read item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(read_path)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019010100_2019010101'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[2208]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab5216e06f44b20be6ee5202018ee7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=672), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "reader2item = {}\n",
    "#file_list = [x for x in os.listdir(read_path) if x.startswith('20190222')]\n",
    "\n",
    "for read_file in tqdm_notebook(file_list[2952:]): #2월~(2952) #2월22~(3456) #2월20~(3408)\n",
    "    try:\n",
    "        file = open(read_path+read_file, 'r')\n",
    "        data_ = file.readlines()\n",
    "    except:\n",
    "        print(read_file)\n",
    "        continue\n",
    "        \n",
    "    file_ts = time.mktime(datetime.datetime.strptime(read_file[-10:], '%Y%m%d%H').timetuple()) + 32400\n",
    "\n",
    "    for line in data_:\n",
    "        tokens = line.split(' ')\n",
    "        try:\n",
    "            reader = reader2id[tokens[0]]\n",
    "        except:\n",
    "            continue\n",
    "        items = [[item_dict[x], file_ts] if item_dict.get(x)!=None else [item_dict['unk'], file_ts] for x in tokens[1:-1]]\n",
    "        \n",
    "        if reader2item.get(reader) != None:\n",
    "            reader2item[reader] = reader2item[reader] + items\n",
    "        else:\n",
    "            reader2item[reader] = items\n",
    "            \n",
    "np.save('/data/private/Arena/prepro_results/reader2item.npy', reader2item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294366, 310759, '@tnrud572_70')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader2item), len(reader2id), item_list[115634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid2followid = {}\n",
    "for data in users_list:\n",
    "    id_ = reader2id[data['id']]\n",
    "    following_list = [writer2id[x] for x in data['following_list']]\n",
    "    userid2followid[id_] = following_list\n",
    "    \n",
    "np.save('/data/private/Arena/prepro_results/userid2followid.npy', userid2followid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec4840a92e54dfca3481cd8e73e9bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=643104), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_keylen = 0\n",
    "for data in tqdm_notebook(metadata_list):\n",
    "    keylen = len(data['keyword_list'])\n",
    "    if max_keylen < keylen:\n",
    "        max_keylen = keylen\n",
    "print(max_keylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reader2item = np.load('/data/private/Arena/prepro_results/reader2item.npy', allow_pickle=True).item()\n",
    "readlen_list = [len(v) for v in reader2item.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(readlen_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Based\n",
    "Train Valid Test data (from 4 to 1 : window size = 5) and Mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, vs in list(reader2item.items()):\n",
    "    for v in vs:        \n",
    "        if v[1] < 1000000000:\n",
    "            print(v, k)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_data = []\n",
    "rnn_valid_data = []\n",
    "rnn_test_data = {}\n",
    "window_size = 5\n",
    "for reader, items_list in reader2item.items():\n",
    "    if not items_list:\n",
    "        continue\n",
    "    items_array = np.array(items_list)\n",
    "    items, read_ts = items_array[:,0].tolist(), items_array[:,1].tolist()\n",
    "\n",
    "    if len(items) < window_size:\n",
    "        items = [item_dict['unk']] * (window_size-len(items)) + items\n",
    "        read_ts = [0] * (window_size-len(read_ts)) + read_ts\n",
    "        \n",
    "    rnn_data = []\n",
    "    for i in range(len(items)-window_size+1):\n",
    "        rnn_data.append([reader, read_ts[i+window_size-1]] + items[i:i+window_size])\n",
    "        \n",
    "    if len(items) > window_size+4:\n",
    "        rnn_train_data += rnn_data[int(len(rnn_data)*0.1):]\n",
    "        rnn_valid_data += rnn_data[:int(len(rnn_data)*0.1)]\n",
    "    else:\n",
    "        rnn_train_data += rnn_data\n",
    "    rnn_test_data[reader] = rnn_data[-1]\n",
    "        \n",
    "np.save('/data/private/Arena/prepro_results/rnn_train_data.npy', rnn_train_data)\n",
    "np.save('/data/private/Arena/prepro_results/rnn_valid_data.npy', rnn_valid_data)\n",
    "##np.save('/data/private/Arena/prepro_results/rnn_test_data.npy', rnn_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(865343, 99912)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rnn_train_data), len(rnn_valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data as not a dictionary (REAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 (3000, 7)\n"
     ]
    }
   ],
   "source": [
    "pred_dev_file = '/data/private/Arena/datasets/predict/dev.users'\n",
    "pred_dev_data = open(pred_dev_file, 'r').readlines()\n",
    "test_data = []\n",
    "a = 0\n",
    "for line in pred_dev_data:\n",
    "    if reader2id.get(line.strip()) != None:\n",
    "        reader = reader2id[line.strip()]\n",
    "        readed = rnn_test_data[reader] if rnn_test_data.get(reader)!=None else [0,0,0,0,0,0,0]\n",
    "    else:\n",
    "        reader = reader2id['unk']\n",
    "        readed = [0,0,0,0,0,0,0]\n",
    "        a += 1\n",
    "    test_data.append(readed)\n",
    "\n",
    "np.save('/data/private/Arena/prepro_results/rnn_test_data.npy', np.array(test_data))\n",
    "print(a, np.array(test_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_dev_file = '/data/private/Arena/datasets/predict/dev.users'\n",
    "# pred_dev_data = open(pred_dev_file, 'r').readlines()\n",
    "\n",
    "# #reader2id = np.load('/data/private/Arena/prepro_results/reader2id.npy', allow_pickle=True).item()\n",
    "# #reader2items = np.load('/data/private/Arena/prepro_results/reader2item.npy', allow_pickle=True).item()\n",
    "# dev_mask = np.ones((len(pred_dev_data), 643105))\n",
    "# for i, line in enumerate(pred_dev_data):\n",
    "#     try:\n",
    "#         readed = reader2items[reader2id[line.strip()]]\n",
    "#         readed = list(set(np.array(readed)[:,0].astype(np.int32).tolist()))\n",
    "#     except:\n",
    "#         continue\n",
    "#     dev_mask[i,readed] = 0\n",
    "# dev_mask[:,0] = 0\n",
    "    \n",
    "# np.save('/data/private/Arena/prepro_results/dev_mask.npy', dev_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Valid Test data and Mask (from 4 to 2 : window size = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_data = []\n",
    "rnn_valid_data = []\n",
    "rnn_test_data = {}\n",
    "window_size = 6\n",
    "\n",
    "for reader, items_list in reader2item.items():\n",
    "    if not items_list:\n",
    "        continue\n",
    "    items_array = np.array(items_list)\n",
    "    items, read_ts = items_array[:,0].tolist(), items_array[:,1].tolist()\n",
    "\n",
    "    if len(items) < window_size:\n",
    "        items = [item_dict['unk']] * (window_size-len(items)) + items\n",
    "        read_ts = [0] * (window_size-len(read_ts)) + read_ts\n",
    "    \n",
    "    rnn_data = []\n",
    "    for i in range(len(items)-window_size+1):\n",
    "        rnn_data.append([reader, read_ts[i+window_size-1]] + items[i:i+window_size])\n",
    "    \n",
    "    if len(items) > window_size+4:\n",
    "        rnn_train_data += rnn_data#[:int(len(rnn_data)*0.9)]\n",
    "        rnn_valid_data += rnn_data[int(len(rnn_data)*0.9):]\n",
    "    else:\n",
    "        rnn_train_data += rnn_data\n",
    "    rnn_test_data[reader] = rnn_data[-1]\n",
    "\n",
    "np.save('/data/private/Arena/prepro_results/rnn_train_data2.npy', rnn_train_data)\n",
    "np.save('/data/private/Arena/prepro_results/rnn_valid_data2.npy', rnn_valid_data)\n",
    "\n",
    "pred_dev_file = '/data/private/Arena/datasets/predict/dev.users'\n",
    "pred_dev_data = open(pred_dev_file, 'r').readlines()\n",
    "test_data = []\n",
    "a = 0\n",
    "for line in pred_dev_data:\n",
    "    if reader2id.get(line.strip()) != None:\n",
    "        reader = reader2id[line.strip()]\n",
    "        readed = rnn_test_data[reader] if rnn_test_data.get(reader)!=None else [0] * (window_size+2)\n",
    "    else:\n",
    "        reader = reader2id['unk']\n",
    "        readed = [0]* (window_size+2)\n",
    "        a += 1\n",
    "    test_data.append(readed)\n",
    "\n",
    "np.save('/data/private/Arena/prepro_results/rnn_test_data2.npy', np.array(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10092798, 1036769)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rnn_train_data), len(rnn_valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Data Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dfe81e8f544a87a5510041551ca281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=310758), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_readers = 310759\n",
    "num_writers = 19066\n",
    "data_list = []\n",
    "\n",
    "for reader_idx in tqdm(range(1, num_readers)):\n",
    "    follow_list = reader2elem[reader_idx]\n",
    "    if np.nonzero(follow_list)[0].shape[0] < 3:\n",
    "        continue\n",
    "\n",
    "    follow_list = np.array(follow_list)[np.nonzero(follow_list)[0]]\n",
    "    np.random.shuffle(follow_list)\n",
    "    negs_list = np.array(\n",
    "                random.sample(list(set(range(num_writers))-set(follow_list)),\n",
    "                              len(follow_list)-1))\n",
    "    for i in range(len(follow_list)-1):\n",
    "        data_list.append([reader_idx, follow_list[i], follow_list[i+1], 1])\n",
    "        data_list.append([reader_idx, follow_list[i], negs_list[i], 0])\n",
    "        \n",
    "data_array = np.array(data_list)\n",
    "np.save('/data/private/Arena/prepro_results/pretrain_data.npy', data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ffbcf89da04ebdb53327070206d73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=643104), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_items = 643105\n",
    "num_magazines = 28130\n",
    "\n",
    "magazine2keyword = {0:[]}\n",
    "for data_ in tqdm(metadata_list):\n",
    "    magazine_id = magazine2id.get(data_['magazine_id'])\n",
    "    if magazine_id == None:\n",
    "        continue\n",
    "    keyword_list = data_['keyword_list']\n",
    "    \n",
    "    if magazine2keyword.get(magazine_id) != None:\n",
    "        magazine2keyword[magazine_id] = list(set(magazine2keyword[magazine_id]+keyword_list))\n",
    "    else:\n",
    "        magazine2keyword[magazine_id] = keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "magazine2keyword[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_min = 1430409600 # 20150501000000 GMT+8\n",
    "ts_list = []\n",
    "for elem in list(item2elem.items()):\n",
    "    ts_list.append((elem[1][6]-ts_min)/8640000)\n",
    "np.save('/data/private/Arena/prepro_results/ts_array.npy', np.array(ts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643105"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
